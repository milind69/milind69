{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4cdbdc09",
      "metadata": {
        "id": "4cdbdc09"
      },
      "source": [
        "### **Objective**\n",
        "You are provided with a dataset of images of plant seedlings at various stages of grown. Each image has a filename that is its unique id. The dataset comprises 12 plant species. The goal of the project is to create a classifier capable of determining a plant's species from a photo.\n",
        "\n",
        "#### **Dataset:**\n",
        "\n",
        "The data file names are:\n",
        "\n",
        "- images.npy - which contains the array of images\n",
        "- Label.csv  - Lables for each image "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4b1b7bfd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b1b7bfd",
        "outputId": "a989bb01-b698-4a7f-bbfc-62ae36d2bb51"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup Done\n"
          ]
        }
      ],
      "source": [
        "#Reading the training images from the path and labelling them into the given categories\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import seaborn as sns # for data visualization \n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.models import Sequential #sequential api for sequential model \n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten #importing different layers \n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation, Input, LeakyReLU,Activation\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical #to perform one-hot encoding \n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from tensorflow.keras.optimizers import RMSprop,Adam #optimiers for optimizing the model\n",
        "from tensorflow.keras.callbacks import EarlyStopping  #regularization method to prevent the overfitting\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import losses, optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "print(\"Setup Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d440545",
      "metadata": {
        "id": "2d440545"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b274f24",
      "metadata": {
        "id": "2b274f24"
      },
      "source": [
        "### **Reading the DataSet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a2a1801",
      "metadata": {
        "id": "9a2a1801"
      },
      "outputs": [],
      "source": [
        "# Read the data file \n",
        "images=np.load('/content/drive/MyDrive/Colab Notebooks/images.npy')\n",
        "plant_seedlings = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Labels.csv')\n",
        "#images=np.load('images.npy')\n",
        "#plant_seedlings = pd.read_csv('Labels.csv')\n",
        "labels = plant_seedlings['Label']\n",
        "# get #of classes\n",
        "classes = list(np.unique(labels))\n",
        "num_of_seedlings = len(images)\n",
        "print(\"There are %d classes and %d images in the dataset\" % (len(classes),len(images)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vZdvuZRyPlyY"
      },
      "id": "vZdvuZRyPlyY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e902d86d",
      "metadata": {
        "id": "e902d86d"
      },
      "outputs": [],
      "source": [
        "print(\"Indexed list of classes\")\n",
        "_=[print(f'{x} - {classes[x]}') for x in range(len(classes))]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d774ddaa",
      "metadata": {
        "id": "d774ddaa"
      },
      "outputs": [],
      "source": [
        "print(\"Percent wise distribution of each class\")\n",
        "print(\"-------------------------------------------\")\n",
        "print(\"{}\".format(plant_seedlings['Label'].value_counts(normalize=True)*100))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Count wise distribution of each class\")\n",
        "print(\"-------------------------------------------\")\n",
        "print(\"{}\".format(plant_seedlings['Label'].value_counts(sort=True)))"
      ],
      "metadata": {
        "id": "AIZOO-Kx_mSI"
      },
      "id": "AIZOO-Kx_mSI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "There is unbalanced distribution of classes, Highest is *Loose Silky-ben*  with 13.76% and lowest is *Maize* with 4.65%"
      ],
      "metadata": {
        "id": "UrXyRYJ_AgQc"
      },
      "id": "UrXyRYJ_AgQc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d91ebb5",
      "metadata": {
        "id": "9d91ebb5"
      },
      "outputs": [],
      "source": [
        "# Build List of List containing HSV image and numberical class value \n",
        "seedlings_data = []\n",
        "grayhsv_data =[]\n",
        "scale = 128\n",
        "for image,label in (list(zip(images,labels))):\n",
        "  try:  \n",
        "    image=cv2.resize(image,(scale,scale))\n",
        "    grayimg=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "    blurr = cv2.GaussianBlur(image,(5,5),0)\n",
        "    #blurr = cv2.GaussianBlur(grayimg,(5,5),0)\n",
        "    hsv = cv2.cvtColor(blurr,cv2.COLOR_BGR2HSV)\n",
        "    #grayhsv = cv2.cvtColor(hsv,cv2.COLOR_BGR2GRAY)\n",
        "    class_num=classes.index(label)\n",
        "    seedlings_data.append([(image,hsv),class_num])\n",
        "    #grayhsv_data.append([(grayimg,grayhsv),class_num])\n",
        "  except:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seedlings_data[0]"
      ],
      "metadata": {
        "id": "6WzR4xztM13k"
      },
      "id": "6WzR4xztM13k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "908b30df",
      "metadata": {
        "id": "908b30df"
      },
      "source": [
        "### **Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e06097d",
      "metadata": {
        "id": "4e06097d"
      },
      "outputs": [],
      "source": [
        "fig1, ax1 = plt.subplots(figsize=(8, 8))\n",
        "ax1=plt.pie(plant_seedlings['Label'].value_counts(), labels=classes,shadow=True, autopct = lambda pct: '{:.2f}%'.format(pct),startangle=90)\n",
        "plt.title(\"Proportion of seedlings in the imageset \", size = 20)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "577993b1",
      "metadata": {
        "id": "577993b1"
      },
      "source": [
        "#### **Print Random Images from each class**\n",
        "\n",
        "**Visualize images randomly from each of the three classes**. The Image matrix is plotted and each row represents two 3 channel images corresponding to one class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b10deff",
      "metadata": {
        "id": "8b10deff"
      },
      "outputs": [],
      "source": [
        "\n",
        "imgx_0 = [imgs[0] for imgs,clsnum in seedlings_data if clsnum == 0] \n",
        "labelx_0 = classes[0]\n",
        "imgx_1 = [imgs[0] for imgs,clsnum in seedlings_data if clsnum == 1] \n",
        "labelx_1 = classes[1]\n",
        "imgx_2 = [imgs[0] for imgs,clsnum in seedlings_data if clsnum == 2] \n",
        "labelx_2 = classes[2]\n",
        "\n",
        "imgx_3 = [imgs[0] for imgs,clsnum in seedlings_data if clsnum == 3] \n",
        "labelx_3 = classes[3]\n",
        "imgx_4 = [imgs[0] for imgs,clsnum in seedlings_data if clsnum == 4] \n",
        "labelx_4 = classes[4]\n",
        "imgx_5 = [imgs[0] for imgs,clsnum in seedlings_data if clsnum == 5] \n",
        "labelx_5 = classes[5]\n",
        "\n",
        "imgx_6 = [imgs[0] for imgs,clsnum in seedlings_data if clsnum == 6] \n",
        "labelx_6 = classes[6]\n",
        "imgx_7 = [imgs[0] for imgs,clsnum in seedlings_data if clsnum == 7] \n",
        "labelx_7 = classes[7]\n",
        "imgx_8 = [imgs[0] for imgs,clsnum in seedlings_data if clsnum == 8] \n",
        "labelx_8 = classes[8]\n",
        "\n",
        "imgx_9 = [imgs[0] for imgs,clsnum in seedlings_data if clsnum == 9] \n",
        "labelx_9 = classes[9]\n",
        "imgx_10 = [imgs[0] for imgs,clsnum in seedlings_data if clsnum == 10] \n",
        "labelx_10 = classes[10]\n",
        "imgx_11 = [imgs[0] for imgs,clsnum in seedlings_data if clsnum == 11] \n",
        "labelx_11 = classes[11]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da400471",
      "metadata": {
        "id": "da400471"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "fig = plt.figure(figsize = (20,9))\n",
        "\n",
        "for count in range(0,2):\n",
        "    ax = fig.add_subplot(4, 6, count+1)\n",
        "    fn=image.array_to_img(imgx_0[np.random.randint(0,len(imgx_0))])\n",
        "    plt.imshow(fn, cmap='gray')\n",
        "    plt.title(labelx_0)\n",
        "    plt.axis('off')\n",
        "    \n",
        "for count in range(0,2):\n",
        "    ax = fig.add_subplot(4, 6, count+3)\n",
        "    fn=image.array_to_img(imgx_1[np.random.randint(0,len(imgx_1))])\n",
        "    plt.imshow(fn, cmap='gray')\n",
        "    plt.title(labelx_1)\n",
        "    plt.axis('off')\n",
        "    \n",
        "for count in range(0,2):\n",
        "    ax = fig.add_subplot(4, 6, count+5)\n",
        "    fn=image.array_to_img(imgx_2[np.random.randint(0,len(imgx_2))])\n",
        "    plt.imshow(fn, cmap='gray')\n",
        "    plt.title(labelx_2)\n",
        "    plt.axis('off')\n",
        "    \n",
        "for count in range(0,2):\n",
        "    ax = fig.add_subplot(4, 6, count+7)\n",
        "    fn=image.array_to_img(imgx_3[np.random.randint(0,len(imgx_3))])\n",
        "    plt.imshow(fn, cmap='gray')\n",
        "    plt.title(labelx_3)\n",
        "    plt.axis('off')\n",
        "\n",
        "for count in range(0,2):\n",
        "    ax = fig.add_subplot(4, 6, count+9)\n",
        "    fn=image.array_to_img(imgx_4[np.random.randint(0,len(imgx_4))])\n",
        "    plt.imshow(fn, cmap='gray')\n",
        "    plt.title(labelx_4)\n",
        "    plt.axis('off')\n",
        "    \n",
        "for count in range(0,2):\n",
        "    ax = fig.add_subplot(4, 6, count+11)\n",
        "    fn=image.array_to_img(imgx_5[np.random.randint(0,len(imgx_5))])\n",
        "    plt.imshow(fn, cmap='gray')\n",
        "    plt.title(labelx_5)\n",
        "    plt.axis('off')\n",
        "    \n",
        "\n",
        "for count in range(0,2):\n",
        "    ax = fig.add_subplot(4, 6, count+13)\n",
        "    fn=image.array_to_img(imgx_6[np.random.randint(0,len(imgx_6))])\n",
        "    plt.imshow(fn, cmap='gray')\n",
        "    plt.title(labelx_6)\n",
        "    plt.axis('off')\n",
        "\n",
        "for count in range(0,2):\n",
        "    ax = fig.add_subplot(4, 6, count+15)\n",
        "    fn=image.array_to_img(imgx_7[np.random.randint(0,len(imgx_7))])\n",
        "    plt.imshow(fn, cmap='gray')\n",
        "    plt.title(labelx_7)\n",
        "    plt.axis('off')\n",
        "    \n",
        "for count in range(0,2):\n",
        "    ax = fig.add_subplot(4, 6, count+17)\n",
        "    fn=image.array_to_img(imgx_8[np.random.randint(0,len(imgx_8))])\n",
        "    plt.imshow(fn, cmap='gray')\n",
        "    plt.title(labelx_8)\n",
        "    plt.axis('off')\n",
        "\n",
        "for count in range(0,2):\n",
        "    ax = fig.add_subplot(4, 6, count+19)\n",
        "    fn=image.array_to_img(imgx_9[np.random.randint(0,len(imgx_9))])\n",
        "    plt.imshow(fn, cmap='gray')\n",
        "    plt.title(labelx_9)\n",
        "    plt.axis('off')\n",
        "    \n",
        "for count in range(0,2):\n",
        "    ax = fig.add_subplot(4, 6, count+21)\n",
        "    fn=image.array_to_img(imgx_10[np.random.randint(0,len(imgx_10))])\n",
        "    plt.imshow(fn, cmap='gray')\n",
        "    plt.title(labelx_10)\n",
        "    plt.axis('off')\n",
        "    \n",
        "for count in range(0,2):\n",
        "    ax = fig.add_subplot(4, 6, count+23)\n",
        "    fn=image.array_to_img(imgx_11[np.random.randint(0,len(imgx_11))])\n",
        "    plt.imshow(fn, cmap='gray')\n",
        "    plt.title(labelx_11)\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9d43a37",
      "metadata": {
        "id": "f9d43a37"
      },
      "source": [
        "#### Image Histogram\n",
        "- Image Histograms shows the distribution on Pixel/Pixel Intensity in the images\n",
        "- Histogram of an image provides a global description of the appearance of an image.\n",
        "- Histogram of an image represents the relative frequency of occurence of various gray levels in an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13b24658",
      "metadata": {
        "scrolled": true,
        "id": "13b24658"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize = (8,4))\n",
        "i=seedlings_data[12][0][0]\n",
        "fig.add_subplot(1,2,1)\n",
        "plt.imshow(i)\n",
        "plt.axis('off')\n",
        "b=i.flatten()\n",
        "#plt.figure(figsize=(4,4), edgecolor='red')\n",
        "fig.add_subplot(1,2,2)\n",
        "n, bins, patches = plt.hist(b, bins=15)\n",
        "plt.xlabel('Pixel value')\n",
        "plt.ylabel('Number of Pixels')\n",
        "plt.title('Histogram of Pixel values')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize = (8,4))\n",
        "i=seedlings_data[12][0][1]\n",
        "fig.add_subplot(1,2,1)\n",
        "plt.imshow(i)\n",
        "plt.axis('off')\n",
        "b=i.flatten()\n",
        "#plt.figure(figsize=(4,4), edgecolor='red')\n",
        "fig.add_subplot(1,2,2)\n",
        "n, bins, patches = plt.hist(b, bins=15)\n",
        "plt.xlabel('Pixel value')\n",
        "plt.ylabel('Number of Pixels')\n",
        "plt.title('Histogram of Pixel values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X5FIrBUQPlY5"
      },
      "id": "X5FIrBUQPlY5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8d5f9e06",
      "metadata": {
        "id": "8d5f9e06"
      },
      "source": [
        "#### Observations:\n",
        "There is case of class imbalance, the % of observations ranges from 13.7% as  high to 4.65% as low , this can bias the prediction towards majority class \n",
        "\n",
        "Sample Printing of images shows that the quality of images not very good and need to be cleaned up to remove the noise, which can be achieved by \n",
        "\n",
        "- Blurring  the images with Gaussian fliter\n",
        "- Convert the RGB images into the HSV\n",
        "- Histogram show higher pixed intensity due to HSV format conversion \n",
        "- This may help identify boudries "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Finding the mean images** for each class of seedlings"
      ],
      "metadata": {
        "id": "ofgFOYnUrNSx"
      },
      "id": "ofgFOYnUrNSx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63e60285",
      "metadata": {
        "id": "63e60285"
      },
      "outputs": [],
      "source": [
        "\n",
        "s_data = []\n",
        "IMG_SIZE=128\n",
        "for image,label in (list(zip(images,labels))):\n",
        "    class_n = classes.index(label)\n",
        "    if class_n == 0:\n",
        "     img_array = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "     new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE)) \n",
        "     \n",
        "     s_data.append([new_array])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(class_d):\n",
        "  sz_data = []\n",
        "  IMG_SIZE=128\n",
        "  for image,label in (list(zip(images,labels))):\n",
        "    class_n = classes.index(label)\n",
        "    if class_n == class_d:\n",
        "     img_array = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "     new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE)) \n",
        "     sz_data.append([new_array])\n",
        "  return sz_data"
      ],
      "metadata": {
        "id": "JgD7I5offUJQ"
      },
      "id": "JgD7I5offUJQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_mean_img(full_mat, title):\n",
        "    # calculate the average\n",
        "    mean_img = np.mean(full_mat, axis = 0)\n",
        "    mean_img = mean_img/255\n",
        "    # reshape it back to a matrix\n",
        "    #mean_img = mean_img.reshape((128,128,3))\n",
        "    #plt.imshow(mean_img, vmin=0, vmax=255, cmap='Greys_r')\n",
        "    plt.imshow(mean_img[0],  cmap='Greys_r')\n",
        "    plt.title(f'Average {title}')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "GnSrDsNheAiR"
      },
      "id": "GnSrDsNheAiR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=plt.figure(figsize=(2,2))\n",
        "label_0_data=get_data(0)\n",
        "find_mean_img(label_0_data, classes[0])\n",
        "\n",
        "label_1_data=get_data(1)\n",
        "fig=plt.figure(figsize=(2,2))\n",
        "find_mean_img(label_1_data, classes[1])\n",
        "\n",
        "label_2_data=get_data(2)\n",
        "fig=plt.figure(figsize=(2,2))\n",
        "find_mean_img(label_2_data, classes[2])\n",
        "\n",
        "label_3_data=get_data(3)\n",
        "fig=plt.figure(figsize=(2,2))\n",
        "find_mean_img(label_3_data, classes[3])"
      ],
      "metadata": {
        "id": "aOTnEjOBf3gp"
      },
      "id": "aOTnEjOBf3gp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_4_data=get_data(4)\n",
        "fig=plt.figure(figsize=(2,2))\n",
        "find_mean_img(label_4_data, classes[4])\n",
        "\n",
        "label_5_data=get_data(5)\n",
        "fig=plt.figure(figsize=(2,2))\n",
        "find_mean_img(label_5_data, classes[5])\n",
        "\n",
        "label_6_data=get_data(6)\n",
        "fig=plt.figure(figsize=(2,2))\n",
        "find_mean_img(label_6_data, classes[6])\n",
        "\n",
        "label_7_data=get_data(7)\n",
        "fig=plt.figure(figsize=(2,2))\n",
        "find_mean_img(label_7_data, classes[7])"
      ],
      "metadata": {
        "id": "eZiA6rKZgSpx"
      },
      "id": "eZiA6rKZgSpx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_8_data=get_data(8)\n",
        "fig=plt.figure(figsize=(2,2))\n",
        "find_mean_img(label_8_data, classes[8])\n",
        "\n",
        "label_9_data=get_data(9)\n",
        "fig=plt.figure(figsize=(2,2))\n",
        "find_mean_img(label_9_data, classes[9])\n",
        "\n",
        "label_10_data=get_data(10)\n",
        "fig=plt.figure(figsize=(2,2))\n",
        "find_mean_img(label_10_data, classes[10])\n",
        "\n",
        "label_11_data=get_data(11)\n",
        "fig=plt.figure(figsize=(2,2))\n",
        "find_mean_img(label_11_data, classes[11])"
      ],
      "metadata": {
        "id": "9hohu5TqgEMD"
      },
      "id": "9hohu5TqgEMD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ebc1e9eb",
      "metadata": {
        "id": "ebc1e9eb"
      },
      "source": [
        "### **Data Preprocessing** \n",
        "Create X features(Images) and y lables from the seedlings data, we shuffle it random so we will get mix of images \n",
        "As observed the quality of images are very poor and also sample distribution in not proper \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5105bf64",
      "metadata": {
        "id": "5105bf64"
      },
      "outputs": [],
      "source": [
        "#Create X and y feature sets orgX is original image sets X is blurred normalize hsv sr\n",
        "X = []\n",
        "y = []\n",
        "orgX =[]\n",
        "np.random.shuffle(seedlings_data)\n",
        "for features,label in seedlings_data:\n",
        "#np.random.shuffle(grayhsv_data)\n",
        "#for features,label in grayhsv_data:\n",
        "    orgX.append(features[0])\n",
        "    X.append(features[1])\n",
        "    y.append(label)\n",
        "X= np.array(X)\n",
        "orgX = np.array(orgX)\n",
        "\n",
        "# Normalizing pixel values  \n",
        "X = X/255.0  \n",
        "orgX = orgX/255.0\n",
        "# image reshaping \n",
        "X = X.reshape(-1,128,128,3)\n",
        "orgX = orgX.reshape(-1,128,128,3)\n",
        "print(X.shape)\n",
        "print(orgX.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fa89f2b",
      "metadata": {
        "id": "3fa89f2b"
      },
      "outputs": [],
      "source": [
        "# Split the data into train and test data set \n",
        "seed=42\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1, random_state=seed,stratify=y) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee32deed",
      "metadata": {
        "id": "ee32deed"
      },
      "outputs": [],
      "source": [
        "#convert target to encoded categorical format \n",
        "encoded = to_categorical(np.array(y_train))\n",
        "y_train_e=encoded\n",
        "encoded_test = to_categorical(np.array(y_test))\n",
        "y_test_e=encoded_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a73f0dbd",
      "metadata": {
        "id": "a73f0dbd"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d5a3253",
      "metadata": {
        "id": "9d5a3253"
      },
      "outputs": [],
      "source": [
        "print(y_train_e.shape)\n",
        "print(y_test_e.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df86a45b",
      "metadata": {
        "id": "df86a45b"
      },
      "source": [
        "### **Model Building** \n",
        "\n",
        "We will be using two types of Deep Neural Networks:\n",
        "\n",
        "- **ANN** (Artificial Neural Network - fully connected)\n",
        "- **CNN** (Convolutional Neural Network)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a83bdcb",
      "metadata": {
        "id": "5a83bdcb"
      },
      "source": [
        "#### **ANN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fa8c5a9",
      "metadata": {
        "id": "1fa8c5a9"
      },
      "outputs": [],
      "source": [
        "#Build the model\n",
        "# 3 layers, 1 layer to flatten the image to a 28 x 28 = 784 vector\n",
        "#           1 layer with 128 neurons and relu function\n",
        "#           1 layer with 10 neurons and softmax function\n",
        "#Create the neural network model\n",
        "def create_model(): \n",
        "        model_ann = keras.Sequential([\n",
        "            keras.layers.Flatten(input_shape=(128,128,3)),\n",
        "            keras.layers.Dense(500,kernel_initializer='he_uniform', activation=tf.nn.relu),\n",
        "            keras.layers.Dropout(0.01),\n",
        "            keras.layers.Dense(700,kernel_initializer='he_uniform', activation=tf.nn.relu),\n",
        "            keras.layers.Dropout(0.01),\n",
        "            keras.layers.Dense(12, kernel_initializer='random_uniform',activation=tf.nn.softmax)\n",
        "        ])\n",
        "        #Compile the model\n",
        "        #The loss function measures how well the model did on training , and then tries \n",
        "        #to improve on it using the optimizer\n",
        "        model_ann.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "        return model_ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "515a1f3f",
      "metadata": {
        "id": "515a1f3f"
      },
      "outputs": [],
      "source": [
        "model_ann=create_model()\n",
        "model_ann.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdb58491",
      "metadata": {
        "id": "fdb58491"
      },
      "outputs": [],
      "source": [
        "#Train the model\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
        "mc = ModelCheckpoint('best_model_ann.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "history=model_ann.fit(X_train, \n",
        "          y_train_e,  #It expects integers because of the sparse_categorical_crossentropy loss function\n",
        "          epochs=200, #number of iterations over the entire dataset to train on\n",
        "          batch_size=100,validation_split=0.2,callbacks=[es, mc],use_multiprocessing=True,verbose=1)#number of samples per gradient update for training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CY4-0PzttALG"
      },
      "id": "CY4-0PzttALG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mFcTMTb-Pny3"
      },
      "id": "mFcTMTb-Pny3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model on test Data\n",
        "model_ann.evaluate(X_test,y_test_e)"
      ],
      "metadata": {
        "id": "I1UpUkM0vlV-"
      },
      "id": "I1UpUkM0vlV-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model_ann=load_model('best_model_ann.h5')"
      ],
      "metadata": {
        "id": "bEk8qeK_RJQn"
      },
      "id": "bEk8qeK_RJQn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict=model_ann.predict(X_test)\n",
        "y_predict = np.argmax(y_predict, axis=1)"
      ],
      "metadata": {
        "id": "Glh1WO9iRX5d"
      },
      "id": "Glh1WO9iRX5d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yRviAmIQR8ux"
      },
      "id": "yRviAmIQR8ux",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm=confusion_matrix(y_test,y_predict)\n",
        "cm"
      ],
      "metadata": {
        "id": "zPvOB2YWRfqt"
      },
      "id": "zPvOB2YWRfqt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VRzKzprXTqjG"
      },
      "id": "VRzKzprXTqjG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,7))\n",
        "import seaborn as sns\n",
        "sns.heatmap(cm, annot=True,vmin=0, vmax=1, cmap='icefire_r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UqyI29trSiB5"
      },
      "id": "UqyI29trSiB5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,y_predict))"
      ],
      "metadata": {
        "id": "PrOoH4gSTrTS"
      },
      "id": "PrOoH4gSTrTS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df=pd.DataFrame({\"y_test\": y_test,\n",
        "              \"y_predict\": y_predict\n",
        "})"
      ],
      "metadata": {
        "id": "fONw2bdlwOnn"
      },
      "id": "fONw2bdlwOnn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "id": "oxEzVBRRxhhU"
      },
      "id": "oxEzVBRRxhhU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=plt.figure(figsize=(10,4))\n",
        "rand_img_num=np.random.randint(1,50)\n",
        "test_img = test_df.iloc[rand_img_num]\n",
        "fig.add_subplot(2,2,1)\n",
        "plt.imshow(X_test[test_img['y_test']])\n",
        "plt.title(classes[test_img['y_test']])\n",
        "fig.add_subplot(2,2,2)\n",
        "plt.imshow(X_test[test_img['y_predict']])\n",
        "plt.title(classes[test_img['y_predict']])\n",
        "plt.show()\n",
        "print(test_img['y_test'])"
      ],
      "metadata": {
        "id": "afPyFI0Z8zgQ"
      },
      "id": "afPyFI0Z8zgQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "xSpYe2ODF7a9"
      },
      "id": "xSpYe2ODF7a9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "ax=sns.stripplot(data=test_df,y='y_test', x='y_predict', jitter=True)\n",
        "plt.title(\"Distribution of Prediction\")\n",
        "plt.ylim(0,12)\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "R1eOxdaKwxAT"
      },
      "id": "R1eOxdaKwxAT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we see here, the **ANN does not show a good test accuracy**, since ANNs are unable to capture correlation characteristics of the image. \n",
        "\n",
        "**Let's try Convolutional Neural Networks, which take in the whole image as a 2D matrix instead.**"
      ],
      "metadata": {
        "id": "TGCR_kn4AfAS"
      },
      "id": "TGCR_kn4AfAS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CNN**"
      ],
      "metadata": {
        "id": "0ZEmll0E9aCS"
      },
      "id": "0ZEmll0E9aCS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN with Dropout - Model 1**"
      ],
      "metadata": {
        "id": "8ZfPtW1u9NTd"
      },
      "id": "8ZfPtW1u9NTd"
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn_d = Sequential()\n",
        "#\n",
        "\n",
        "model_cnn_d.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (128,128,3)))\n",
        "model_cnn_d.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_cnn_d.add(Dropout(0.25))\n",
        "#\n",
        "model_cnn_d.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
        "model_cnn_d.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model_cnn_d.add(Dropout(0.25))\n",
        "#\n",
        "model_cnn_d.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
        "model_cnn_d.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model_cnn_d.add(Dropout(0.3))\n",
        "#\n",
        "model_cnn_d.add(Conv2D(filters = 128, kernel_size = (2,2),padding = 'Same', activation ='relu'))\n",
        "model_cnn_d.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model_cnn_d.add(Dropout(0.3))\n",
        "\n",
        "#\n",
        "model_cnn_d.add(Conv2D(filters = 256, kernel_size = (2,2),padding = 'Same', activation ='relu'))\n",
        "model_cnn_d.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model_cnn_d.add(Dropout(0.3))\n",
        "\n",
        "# \n",
        "model_cnn_d.add(Flatten())\n",
        "model_cnn_d.add(Dense(1024, activation = \"relu\"))\n",
        "model_cnn_d.add(Dropout(0.5))\n",
        "model_cnn_d.add(Dense(12, activation = \"softmax\"))\n",
        "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
        "model_cnn_d.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "epochs = 200  \n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=7)\n",
        "mc = ModelCheckpoint('best_model_cnn_d.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "history_cnn_d=model_cnn_d.fit(X_train, \n",
        "          y_train_e,  #It expects integers because of the sparse_categorical_crossentropy loss function\n",
        "          epochs=30, #number of iterations over the entire dataset to train on\n",
        "          batch_size=64,validation_split=0.20,callbacks=[es, mc],use_multiprocessing=True,verbose=1)#number of samples per gradient update for training  \n"
      ],
      "metadata": {
        "id": "K_OTIUsA9MXO"
      },
      "id": "K_OTIUsA9MXO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history_cnn_d.history['accuracy'])\n",
        "plt.plot(history_cnn_d.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IJiY5S1tG-6c"
      },
      "id": "IJiY5S1tG-6c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model_cnn_d=load_model('best_model_cnn_d.h5')"
      ],
      "metadata": {
        "id": "W7JQbUQBHNUX"
      },
      "id": "W7JQbUQBHNUX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model on test Data\n",
        "model_cnn_d.evaluate(X_test,y_test_e)"
      ],
      "metadata": {
        "id": "PNp6ZbrDHQNO"
      },
      "id": "PNp6ZbrDHQNO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict=model_cnn_d.predict(X_test)\n",
        "y_predict = np.argmax(y_predict, axis=1)"
      ],
      "metadata": {
        "id": "IfQjzc2ZHTna"
      },
      "id": "IfQjzc2ZHTna",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm=confusion_matrix(y_test,y_predict)\n",
        "cm"
      ],
      "metadata": {
        "id": "wG9NKrpuHWxh"
      },
      "id": "wG9NKrpuHWxh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,7))\n",
        "plt.title(\"Heatmap Test Data\")\n",
        "import seaborn as sns\n",
        "sns.heatmap(cm, annot=True,vmin=0, vmax=1, cmap='icefire_r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qi2oDEqoHZtE"
      },
      "id": "qi2oDEqoHZtE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,y_predict))"
      ],
      "metadata": {
        "id": "KOUCBxXEHczL"
      },
      "id": "KOUCBxXEHczL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df_cnn_d=pd.DataFrame({\"y_test\": y_test,\n",
        "              \"y_predict\": y_predict\n",
        "})\n",
        "test_df_cnn_d.head(5)"
      ],
      "metadata": {
        "id": "ti3rnW8FHfhc"
      },
      "id": "ti3rnW8FHfhc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=plt.figure(figsize=(10,4))\n",
        "rand_img_num=np.random.randint(1,50)\n",
        "test_img = test_df_cnn_d.iloc[rand_img_num]\n",
        "fig.add_subplot(2,2,1)\n",
        "plt.imshow(X_test[test_img['y_test']])\n",
        "plt.title(classes[test_img['y_test']])\n",
        "fig.add_subplot(2,2,2)\n",
        "plt.imshow(X_test[test_img['y_predict']])\n",
        "plt.title(classes[test_img['y_predict']])\n",
        "plt.show()\n",
        "print(test_img['y_test'])"
      ],
      "metadata": {
        "id": "uCPWrhuMKqF9"
      },
      "id": "uCPWrhuMKqF9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "ax=sns.stripplot(data=test_df_cnn_d,y='y_test', x='y_predict', jitter=True)\n",
        "plt.title(\"Distribution of Prediction\")\n",
        "plt.ylim(0,12)\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "cZlKWoOBHiVa"
      },
      "id": "cZlKWoOBHiVa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "4OuT5aeGQole"
      },
      "id": "4OuT5aeGQole",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN with Dropout and BatchNormalization - Model 2**"
      ],
      "metadata": {
        "id": "HXX_TOgD87uZ"
      },
      "id": "HXX_TOgD87uZ"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model_cnn_db = Sequential()\n",
        "#\n",
        "model_cnn_db.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (128,128,3)))\n",
        "model_cnn_db.add(MaxPool2D(pool_size=(2,2)))\n",
        "#model_cnn_db.add(BatchNormalization(axis=3))\n",
        "model_cnn_db.add(Dropout(0.25))\n",
        "#\n",
        "#model_cnn_db.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
        "model_cnn_db.add(Conv2D(filters = 128, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n",
        "model_cnn_db.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "#model_cnn_db.add(BatchNormalization(axis=3))\n",
        "model_cnn_db.add(Dropout(0.25))\n",
        "#\n",
        "#model_cnn_db.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
        "model_cnn_db.add(Conv2D(filters = 128, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n",
        "model_cnn_db.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model_cnn_db.add(BatchNormalization(axis=3))\n",
        "model_cnn_db.add(Dropout(0.3))\n",
        "#\n",
        "#model_cnn_db.add(Conv2D(filters = 128, kernel_size = (2,2),padding = 'Same',  activation ='relu'))  \n",
        "model_cnn_db.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',  activation ='relu'))                 \n",
        "model_cnn_db.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "#model.add(BatchNormalization(axis=3))\n",
        "model_cnn_db.add(Dropout(0.3))\n",
        "\n",
        "#\n",
        "#model.add(Conv2D(filters = 256, kernel_size = (2,2),padding = 'Same',  activation ='relu'))\n",
        "model_cnn_db.add(Conv2D(filters = 256, kernel_size = (3,3),padding = 'Same',  activation ='relu'))\n",
        "model_cnn_db.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model_cnn_db.add(BatchNormalization(axis=3))\n",
        "\n",
        "# \n",
        "model_cnn_db.add(Flatten())\n",
        "model_cnn_db.add(Dense(1024, activation = \"relu\"))\n",
        "#model_cnn_db.add(Dropout(0.5))\n",
        "model_cnn_db.add(Dense(12, activation = \"softmax\"))\n",
        "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
        "model_cnn_db.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "epochs = 200  \n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=7)\n",
        "mc = ModelCheckpoint('best_model_db.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True,)\n",
        "lrr = ReduceLROnPlateau(monitor='val_loss',  patience=3, verbose=1, factor=0.4, min_lr=0.00001)\n",
        "lrr1 = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.1)\n",
        "\n",
        "history_cnn_db=model_cnn_db.fit(X_train, \n",
        "          y_train_e,  #It expects integers because of the sparse_categorical_crossentropy loss function\n",
        "          epochs=30, #number of iterations over the entire dataset to train on\n",
        "          batch_size=64,\n",
        "          validation_split=0.20,callbacks=[es, mc,],use_multiprocessing=True,verbose=1)#number of samples per gradient update for training  \n"
      ],
      "metadata": {
        "id": "9WpQwGTsAkWJ"
      },
      "id": "9WpQwGTsAkWJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history_cnn_db.history['accuracy'])\n",
        "plt.plot(history_cnn_db.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dXBkJpD0Ctqd"
      },
      "id": "dXBkJpD0Ctqd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model_cnn_db=load_model('best_model_db.h5')"
      ],
      "metadata": {
        "id": "SCE9sxu8tq-A"
      },
      "id": "SCE9sxu8tq-A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model on test Data\n",
        "model_cnn_db.evaluate(X_test,y_test_e)"
      ],
      "metadata": {
        "id": "t1lxEn0QCzY0"
      },
      "id": "t1lxEn0QCzY0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = model_cnn_db.predict(X_test)\n",
        "y_predict = np.argmax(y_predict, axis=1)"
      ],
      "metadata": {
        "id": "SyLvHIgmC4eG"
      },
      "id": "SyLvHIgmC4eG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm=confusion_matrix(y_test,y_predict)\n",
        "cm"
      ],
      "metadata": {
        "id": "nQl1BQ6PC8sn"
      },
      "id": "nQl1BQ6PC8sn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,7))\n",
        "plt.title(\"Heatmap Test Data\")\n",
        "import seaborn as sns\n",
        "sns.heatmap(cm, annot=True,vmin=0, vmax=1, cmap='icefire_r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WOGLRUV4C_t-"
      },
      "id": "WOGLRUV4C_t-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,y_predict))"
      ],
      "metadata": {
        "id": "SIZc2bZKDMVf"
      },
      "id": "SIZc2bZKDMVf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df_db=pd.DataFrame({\"y_test\": y_test,\n",
        "              \"y_predict\": y_predict\n",
        "})\n",
        "test_df_db.head(10)"
      ],
      "metadata": {
        "id": "v5Wkzl3fDYqF"
      },
      "id": "v5Wkzl3fDYqF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=plt.figure(figsize=(10,4))\n",
        "rand_img_num=np.random.randint(1,50)\n",
        "test_img = test_df_db.iloc[rand_img_num]\n",
        "fig.add_subplot(2,2,1)\n",
        "plt.imshow(X_test[test_img['y_test']])\n",
        "plt.title(classes[test_img['y_test']])\n",
        "fig.add_subplot(2,2,2)\n",
        "plt.imshow(X_test[test_img['y_predict']])\n",
        "plt.title(classes[test_img['y_predict']])\n",
        "plt.show()\n",
        "print(test_img['y_test'])"
      ],
      "metadata": {
        "id": "c7P04LoJxhPY"
      },
      "id": "c7P04LoJxhPY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "ax=sns.stripplot(data=test_df_db,y='y_test', x='y_predict', jitter=True, dodge=True)\n",
        "#ax=sns.violinplot(data=test_df_db,y='y_test', x='y_predict', jitter=True, dodge=True)\n",
        "plt.title(\"Distribution of Prediction\")\n",
        "plt.ylim(0,15)\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "skjMqOnIDhi8"
      },
      "id": "skjMqOnIDhi8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN with Dropout and Data Agumenation - Model 3**"
      ],
      "metadata": {
        "id": "duJB4sLWLx8E"
      },
      "id": "duJB4sLWLx8E"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5pbbVCG1M8aI"
      },
      "id": "5pbbVCG1M8aI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_dg=X_train.copy()"
      ],
      "metadata": {
        "id": "xLzmldKoP7hz"
      },
      "id": "xLzmldKoP7hz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_dg.shape"
      ],
      "metadata": {
        "id": "pNRo6BawTEKb"
      },
      "id": "pNRo6BawTEKb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rotation_range = 180,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,vertical_flip = True,width_shift_range = 0.1,height_shift_range = 0.1)\n"
      ],
      "metadata": {
        "id": "GeYLWusKL8cR"
      },
      "id": "GeYLWusKL8cR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen.fit(X_train_dg)"
      ],
      "metadata": {
        "id": "y2UMVOxrThYt"
      },
      "id": "y2UMVOxrThYt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn_da = Sequential()\n",
        "#\n",
        "\n",
        "model_cnn_da.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (128,128,3)))\n",
        "model_cnn_da.add(MaxPool2D(pool_size=(2,2)))\n",
        "model_cnn_da.add(Dropout(0.25))\n",
        "#\n",
        "model_cnn_da.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
        "model_cnn_da.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model_cnn_da.add(Dropout(0.25))\n",
        "#\n",
        "model_cnn_da.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
        "model_cnn_da.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model_cnn_da.add(Dropout(0.3))\n",
        "#\n",
        "model_cnn_da.add(Conv2D(filters = 128, kernel_size = (2,2),padding = 'Same', activation ='relu'))\n",
        "model_cnn_da.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model_cnn_da.add(Dropout(0.3))\n",
        "\n",
        "#\n",
        "model_cnn_da.add(Conv2D(filters = 256, kernel_size = (2,2),padding = 'Same', activation ='relu'))\n",
        "model_cnn_da.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model_cnn_da.add(Dropout(0.3))\n",
        "\n",
        "# \n",
        "model_cnn_da.add(Flatten())\n",
        "model_cnn_da.add(Dense(1024, activation = \"relu\"))\n",
        "model_cnn_da.add(Dropout(0.5))\n",
        "model_cnn_da.add(Dense(12, activation = \"softmax\"))\n",
        "optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
        "model_cnn_da.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "epochs = 200  \n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=7)\n",
        "mc = ModelCheckpoint('best_model_da.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "history_cnn_da=model_cnn_da.fit(X_train_dg, \n",
        "          y_train_e,  #It expects integers because of the sparse_categorical_crossentropy loss function\n",
        "          epochs=30, #number of iterations over the entire dataset to train on\n",
        "          batch_size=64,validation_split=0.20,callbacks=[es, mc],use_multiprocessing=True,verbose=1)#number of samples per gradient update for training  "
      ],
      "metadata": {
        "id": "-fAjMkaINils"
      },
      "id": "-fAjMkaINils",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history_cnn_da.history['accuracy'])\n",
        "plt.plot(history_cnn_da.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MWsDuFFzN7Oc"
      },
      "id": "MWsDuFFzN7Oc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model_cnn_da=load_model('best_model_da.h5')"
      ],
      "metadata": {
        "id": "vbH3DMJvOErJ"
      },
      "id": "vbH3DMJvOErJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model on test Data\n",
        "model_cnn_da.evaluate(X_test,y_test_e)"
      ],
      "metadata": {
        "id": "3o_OfEj5OKq6"
      },
      "id": "3o_OfEj5OKq6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = model_cnn_da.predict(X_test)\n",
        "y_predict = np.argmax(y_predict, axis=1)"
      ],
      "metadata": {
        "id": "8Z6GaD1HOe-q"
      },
      "id": "8Z6GaD1HOe-q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm=confusion_matrix(y_test,y_predict)\n",
        "cm"
      ],
      "metadata": {
        "id": "AEo93Y2iOkmO"
      },
      "id": "AEo93Y2iOkmO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,7))\n",
        "plt.title(\"Heatmap Test Data\")\n",
        "import seaborn as sns\n",
        "sns.heatmap(cm, annot=True,vmin=0, vmax=1, cmap='icefire_r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FxONhdCZOoRp"
      },
      "id": "FxONhdCZOoRp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,y_predict))"
      ],
      "metadata": {
        "id": "kSXkD3NfOsGd"
      },
      "id": "kSXkD3NfOsGd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df_da=pd.DataFrame({\"y_test\": y_test,\n",
        "              \"y_predict\": y_predict\n",
        "})\n",
        "test_df_da.head(10)"
      ],
      "metadata": {
        "id": "CuayuEsJO7od"
      },
      "id": "CuayuEsJO7od",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=plt.figure(figsize=(10,4))\n",
        "rand_img_num=np.random.randint(1,50)\n",
        "test_img = test_df_da.iloc[rand_img_num]\n",
        "fig.add_subplot(2,2,1)\n",
        "plt.imshow(X_test[test_img['y_test']])\n",
        "plt.title(classes[test_img['y_test']])\n",
        "fig.add_subplot(2,2,2)\n",
        "plt.imshow(X_test[test_img['y_predict']])\n",
        "plt.title(classes[test_img['y_predict']])\n",
        "plt.show()\n",
        "print(test_img['y_test'])"
      ],
      "metadata": {
        "id": "n4hl6IhlOvjH"
      },
      "id": "n4hl6IhlOvjH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xing=X_test*255"
      ],
      "metadata": {
        "id": "ueAGfg9Ao2zT"
      },
      "id": "ueAGfg9Ao2zT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "ax=sns.stripplot(data=test_df_da,y='y_test', x='y_predict', jitter=True, dodge=True)\n",
        "#ax=sns.violinplot(data=test_df_da,y='y_test', x='y_predict', jitter=True, dodge=True)\n",
        "plt.title(\"Distribution of Prediction\")\n",
        "plt.ylim(0,15)\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "u2xwXxBkW21K"
      },
      "id": "u2xwXxBkW21K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%shell\n",
        "#jupyter nbconvert --to html '/content/drive/MyDrive/Colab Notebooks/plant-seedlings.ipynb'"
      ],
      "metadata": {
        "id": "dU70IPVJWCXE"
      },
      "id": "dU70IPVJWCXE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_img=[]\n",
        "for img in X_train:\n",
        "  vggx_img = cv2.resize(img,(224,224))\n",
        "  vgg_img.append(vggx_img)"
      ],
      "metadata": {
        "id": "NweGUBk7GD7B"
      },
      "id": "NweGUBk7GD7B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Av0idErCHzoa"
      },
      "id": "Av0idErCHzoa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "PKc7Ot2JHMiE"
      },
      "id": "PKc7Ot2JHMiE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "model_vgg = VGG16()\n",
        "print(model_vgg.summary())"
      ],
      "metadata": {
        "id": "ALdNL40Z9yCA"
      },
      "id": "ALdNL40Z9yCA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_vgg=model_vgg.predict(X_test)"
      ],
      "metadata": {
        "id": "nAnVhWa5-Kqm"
      },
      "id": "nAnVhWa5-Kqm",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "plant-seedlings.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}