{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/milind69/milind69/blob/main/all_bank_customer_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b4c39b6",
      "metadata": {
        "id": "5b4c39b6"
      },
      "source": [
        "### Description\n",
        "Context\n",
        "AllLife Bank wants to focus on its credit card customer base in the next financial year. They have been advised by their marketing research team, that the penetration in the market can be improved. Based on this input, the Marketing team proposes to run personalized campaigns to target new customers as well as upsell to existing customers. Another insight from the market research was that the customers perceive the support services of the back poorly. Based on this, the Operations team wants to upgrade the service delivery model, to ensure that customer queries are resolved faster. Head of Marketing and Head of Delivery both decide to reach out to the Data Science team for help\n",
        "\n",
        " \n",
        "\n",
        "### Objective\n",
        "To identify different segments in the existing customer, based on their spending patterns as well as past interaction with the bank, using clustering algorithms, and provide recommendations to the bank on how to better market to and service these customers.\n",
        "\n",
        " \n",
        "\n",
        "### Data Description\n",
        "The data provided is of various customers of a bank and their financial attributes like credit limit, the total number of credit cards the customer has, and different channels through which customers have contacted the bank for any queries (including visiting the bank, online and through a call center).\n",
        "\n",
        "### Data Dictionary\n",
        "\n",
        "- Sl_No: Primary key of the records\n",
        "- Customer Key: Customer identification number\n",
        "- Average Credit Limit: Average credit limit of each customer for all credit cards\n",
        "- Total credit cards: Total number of credit cards possessed by the customer\n",
        "- Total visits bank: Total number of visits that customer made (yearly) personally to the bank\n",
        "- Total visits online: Total number of visits or online logins made by the customer (yearly)\n",
        "- Total calls made: Total number of calls made by the customer to the bank or its customer service department (yearly)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6877069",
      "metadata": {
        "id": "b6877069"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32964f4e",
      "metadata": {
        "id": "32964f4e"
      },
      "outputs": [],
      "source": [
        "# this will help in making the Python code more structured automatically (good coding practice)\n",
        "# %reload_ext nb_black\n",
        "\n",
        "# Library to suppress warnings or deprecation notes\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Removes the limit for the number of displayed columns\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "# Sets the limit for the number of displayed rows\n",
        "pd.set_option(\"display.max_rows\", 200)\n",
        "\n",
        "import numpy as np\n",
        "import missingno as msg\n",
        "from scipy import stats as st\n",
        "import pandas_profiling\n",
        "import altair as alt\n",
        "import math\n",
        "\n",
        "\n",
        "# libaries to help with data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(color_codes=True)\n",
        "sns.set_style(\"whitegrid\")\n",
        "# sns.set(style=\"ticks\")\n",
        "\n",
        "\n",
        "# Libraries to build decision tree classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression, Lasso, Ridge, RidgeClassifier\n",
        "\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    GridSearchCV,\n",
        "    RandomizedSearchCV,\n",
        "    KFold,\n",
        "    cross_val_score,\n",
        "    LeaveOneOut,\n",
        "    StratifiedKFold,\n",
        ")\n",
        "\n",
        "\n",
        "# To get diferent metric scores\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    accuracy_score,\n",
        "    recall_score,\n",
        "    precision_score,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    plot_confusion_matrix,\n",
        "    precision_recall_curve,\n",
        "    roc_curve,\n",
        "    make_scorer,\n",
        "    classification_report,\n",
        ")\n",
        "\n",
        "\n",
        "from pandas_profiling import ProfileReport\n",
        "\n",
        "\n",
        "from sklearn.ensemble import (\n",
        "    BaggingClassifier,\n",
        "    RandomForestClassifier,\n",
        "    AdaBoostClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    StackingClassifier,\n",
        ")\n",
        "\n",
        "from sklearn.ensemble._forest import ForestClassifier, ForestRegressor\n",
        "\n",
        "# import treeinterpreter\n",
        "\n",
        "from sklearn.neighbors import (\n",
        "    KNeighborsClassifier,\n",
        "    KNeighborsRegressor,\n",
        "    KNeighborsTransformer,\n",
        "    kneighbors_graph,\n",
        ")\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.impute import SimpleImputer, MissingIndicator\n",
        "\n",
        "from sklearn.preprocessing import (\n",
        "    MinMaxScaler,\n",
        "    OneHotEncoder,\n",
        "    OrdinalEncoder,  # for features\n",
        "    StandardScaler,\n",
        "    PolynomialFeatures,\n",
        "    LabelEncoder,  # convert yes=1 no=0 data alphabetical for targets\n",
        "    RobustScaler,\n",
        ")\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# We can use Dummy for Baseline\n",
        "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics import SCORERS\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score, silhouette_samples\n",
        "from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "# to visualize the elbow curve and silhouette scores\n",
        "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage, cophenet\n",
        "\n",
        "# to compute distances\n",
        "from scipy.spatial.distance import cdist, pdist\n",
        "\n",
        "print(\"Setup Done!!!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbb3692c",
      "metadata": {
        "id": "bbb3692c"
      },
      "outputs": [],
      "source": [
        "# function to plot a boxplot and a histogram along the same scale.\n",
        "\n",
        "\n",
        "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
        "    \"\"\"\n",
        "    Boxplot and histogram combined\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    figsize: size of figure (default (12,7))\n",
        "    kde: whether to the show density curve (default False)\n",
        "    bins: number of bins for histogram (default None)\n",
        "    \"\"\"\n",
        "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
        "        nrows=2,  # Number of rows of the subplot grid= 2\n",
        "        sharex=True,  # x-axis will be shared among all subplots\n",
        "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
        "        figsize=figsize,\n",
        "    )  # creating the 2 subplots\n",
        "    sns.boxplot(\n",
        "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
        "    )  # boxplot will be created and a star will indicate the mean value of the column\n",
        "    sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\"winter\"\n",
        "    ) if bins else sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
        "    )  # For histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
        "    )  # Add mean to the histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
        "    )  # Add median to the histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aee7eb3",
      "metadata": {
        "id": "7aee7eb3"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel(\"Credit Card Customer Data.xlsx\", engine=\"openpyxl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47fc34d0",
      "metadata": {
        "id": "47fc34d0"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12616139",
      "metadata": {
        "id": "12616139"
      },
      "outputs": [],
      "source": [
        "print(\"There are {0} observations and {1} features\".format(df.shape[0], df.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b778dd28",
      "metadata": {
        "id": "b778dd28"
      },
      "outputs": [],
      "source": [
        "print(f\"There are duplicated rows: {df.duplicated().any()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23af6caf",
      "metadata": {
        "id": "23af6caf"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "939af94e",
      "metadata": {
        "id": "939af94e"
      },
      "outputs": [],
      "source": [
        "# ProfileReport(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "953ab35d",
      "metadata": {
        "id": "953ab35d"
      },
      "outputs": [],
      "source": [
        "df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3f179a6",
      "metadata": {
        "id": "f3f179a6"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# for x, y in dict(df.isnull().mean()).items():\n",
        "#   print(x, y)\n",
        "\n",
        "_ = [\n",
        "    print(f\"There are {y}% missing rows in {x} \")\n",
        "    for x, y in dict(df.isnull().mean()).items()\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb2397f1",
      "metadata": {
        "id": "fb2397f1"
      },
      "outputs": [],
      "source": [
        "## The columns Sl_no is of no use we can drop it\n",
        "df.drop(\"Sl_No\", axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f616499",
      "metadata": {
        "id": "5f616499"
      },
      "source": [
        "###  Let us check if customer Key has duplicate records,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dca371f9",
      "metadata": {
        "id": "dca371f9"
      },
      "outputs": [],
      "source": [
        "df[\"Customer Key\"].duplicated().any()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d288837a",
      "metadata": {
        "id": "d288837a"
      },
      "outputs": [],
      "source": [
        "# Check Which Keys are duplicate Keys ...\n",
        "print(\n",
        "    f' Duplicate customer keys are {list(df.loc[df[\"Customer Key\"].duplicated() == True, \"Customer Key\"])}'\n",
        ")\n",
        "df.loc[\n",
        "    df[\"Customer Key\"].isin(\n",
        "        list(df.loc[df[\"Customer Key\"].duplicated() == True, \"Customer Key\"])\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfea9ba5",
      "metadata": {
        "id": "cfea9ba5"
      },
      "source": [
        "#### Customer Key has few duplicate ids , we will drop one duplication row , use keep=First, and create new dataframe , we will use this DataFrame for analysis \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45bb2c8e",
      "metadata": {
        "id": "45bb2c8e"
      },
      "outputs": [],
      "source": [
        "dfx = df.loc[~df[\"Customer Key\"].duplicated() == True]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "989000fd",
      "metadata": {
        "id": "989000fd"
      },
      "outputs": [],
      "source": [
        "dfx.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c9ce88d",
      "metadata": {
        "id": "2c9ce88d"
      },
      "outputs": [],
      "source": [
        "dfx.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06eb98d6",
      "metadata": {
        "id": "06eb98d6"
      },
      "outputs": [],
      "source": [
        "for col in df.columns:\n",
        "    print(\"-\" * 80)\n",
        "    print(df[col].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d85821ec",
      "metadata": {
        "id": "d85821ec"
      },
      "outputs": [],
      "source": [
        "for col in df.columns:\n",
        "    print(\"-\" * 80)\n",
        "    print(col)\n",
        "    print(df[col].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75abbd5b",
      "metadata": {
        "id": "75abbd5b"
      },
      "source": [
        "### Observations:\n",
        " - Total_visits_bank , Total_visits_online , Total_calls_made have minimum values as zero , which looks valid observationb so we will not delete or impute it\n",
        " - There were no duplicate record in Dataframe \n",
        " - Customer key was duplicated but could be valid , we will drop duplicate customer key for analysis \n",
        " - We will bring duplicate Customer key back again as it could be valid record \n",
        " - There are no missing value\n",
        " - There are no out of bound values , all outliers so far look valid "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47812b13",
      "metadata": {
        "id": "47812b13"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ad604a6",
      "metadata": {
        "id": "8ad604a6"
      },
      "source": [
        "### Univariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c980343",
      "metadata": {
        "id": "3c980343"
      },
      "outputs": [],
      "source": [
        "# selecting numerical columns\n",
        "num_col = dfx.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "for item in num_col:\n",
        "    fig = plt.figure()\n",
        "    histogram_boxplot(dfx, item, figsize=(5, 5), kde=True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "773f32a5",
      "metadata": {
        "scrolled": true,
        "id": "773f32a5"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20, 10))\n",
        "numcol = [\n",
        "    \"Total_Credit_Cards\",\n",
        "    \"Total_visits_bank\",\n",
        "    \"Total_visits_online\",\n",
        "    \"Total_calls_made\",\n",
        "]\n",
        "for i, col in enumerate(numcol):\n",
        "    ax = fig.add_subplot(2, 2, i + 1)\n",
        "    sns.countplot(\n",
        "        data=dfx, x=col, palette=\"Paired\", ax=ax,\n",
        "    )\n",
        "    for p in ax.patches:\n",
        "        label = \"{:.1f}%\".format(100 * p.get_height() / len(dfx))\n",
        "        x = p.get_x() + p.get_width() / 2  # width of the plot\n",
        "        y = p.get_height() + 1  # height of the plot\n",
        "\n",
        "        ax.annotate(\n",
        "            label,\n",
        "            (x, y),\n",
        "            ha=\"center\",\n",
        "            va=\"center\",\n",
        "            size=12,\n",
        "            xytext=(0, 5),\n",
        "            textcoords=\"offset points\",\n",
        "        )  # annotate the p"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d922dfdd",
      "metadata": {
        "id": "d922dfdd"
      },
      "source": [
        "### Observations:\n",
        " - There are outliers in Avg Credit Limit and Total Visits online but looks all valid we will keep it\n",
        " - in average 4 or less calls were made by customers\n",
        " - It looks like the higher number of credit card holders have higher Avg Credit Limit and make use of Online banking more , possibly to check expenditure ,increase the credit limit \n",
        " - 66% Customer hold 4 or more Credit Cards \n",
        " - 23% Customer visited bank personally twice in a year 15% made 5 visits \n",
        " - 22% customer did not do any online activity, while 68% customers made between 1-5 online activity\n",
        " - Bank made 4 or less calls per customer in an year \n",
        " - There are outliers in Avg_Credit_Limit and Total_visits_online but that do seems to be a valid data, as we find some relation with Total_Credit_Cards  We will keep Outliers "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d890d10",
      "metadata": {
        "id": "9d890d10"
      },
      "source": [
        "### Bivariate Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddade017",
      "metadata": {
        "id": "ddade017"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(dfx, diag_kind=\"kde\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c252a1d1",
      "metadata": {
        "id": "c252a1d1"
      },
      "source": [
        "### Observations:\n",
        "- Total_visits_online and Avg_Credit_Limit Right skewed. More and More user should be encoraged to visit online for more business \n",
        "- Total_calls_made vs Total_visit_online show two major cluster , less online visitors made more support  calls. \n",
        "- Similar two cluster groups are seen with many features ( Intertesing to see how they will be clustred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec866ce6",
      "metadata": {
        "id": "ec866ce6"
      },
      "outputs": [],
      "source": [
        "dfx.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27fa37dc",
      "metadata": {
        "id": "27fa37dc"
      },
      "outputs": [],
      "source": [
        "found = 0\n",
        "corcols = list(dfx.corr().columns)\n",
        "for colsx in corcols:\n",
        "    tempxs = [x for x in corcols if x != colsx]\n",
        "    for temps in tempxs:\n",
        "        corval = dfx[[colsx, temps]].corr()[colsx][1]\n",
        "        if abs(corval) > 0.95:\n",
        "            print(f\"corelation value between {colsx} and {temps} is {corval:0.2f}\")\n",
        "            found += 1\n",
        "if not found:\n",
        "    print(f\"no high correlation between features found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3109102",
      "metadata": {
        "id": "f3109102"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(dfx.corr(), vmin=-1, vmax=1, annot=True, cmap=cm.Accent_r)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1b12f26",
      "metadata": {
        "id": "e1b12f26"
      },
      "source": [
        "### Observations:\n",
        "- No specific High correlation found between two features "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee372977",
      "metadata": {
        "id": "ee372977"
      },
      "outputs": [],
      "source": [
        "# fig, ax = plt.subplots(111,figsize=(10, 10))\n",
        "fig = plt.figure(figsize=(12, 4))\n",
        "sns.barplot(\n",
        "    data=dfx,\n",
        "    x=\"Total_visits_bank\",\n",
        "    y=\"Total_visits_online\",\n",
        "    hue=\"Total_Credit_Cards\",\n",
        "    ci=None,\n",
        ")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "309d2ff8",
      "metadata": {
        "id": "309d2ff8"
      },
      "outputs": [],
      "source": [
        "# fig, ax = plt.subplots(111,figsize=(10, 10))\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "sns.barplot(data=dfx, x=\"Total_Credit_Cards\", y=\"Avg_Credit_Limit\", ci=None)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cb5be39",
      "metadata": {
        "id": "2cb5be39"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(6, 4))\n",
        "sns.barplot(data=dfx, x=\"Total_Credit_Cards\", y=\"Total_calls_made\", ci=None)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66aaccc0",
      "metadata": {
        "id": "66aaccc0"
      },
      "source": [
        "### Observations:\n",
        "- customer with 8 or more credit cards used online banking more that others\n",
        "- Customer with 8 or more Credit cards have higher credit limits\n",
        "- More support calls were made by Customer with 4 or less credit cards"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "697c6b67",
      "metadata": {
        "id": "697c6b67"
      },
      "source": [
        "### Data Preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2457686",
      "metadata": {
        "id": "f2457686"
      },
      "outputs": [],
      "source": [
        "# No outlier treament needed\n",
        "# we will not drop duplicate customer ids as that could be valid entries\n",
        "# Drop Customer Key colums from clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46a75cef",
      "metadata": {
        "id": "46a75cef"
      },
      "outputs": [],
      "source": [
        "custdata = df.drop(\"Customer Key\", axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6f56b6f",
      "metadata": {
        "id": "e6f56b6f"
      },
      "outputs": [],
      "source": [
        "custdata.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cca1565f",
      "metadata": {
        "id": "cca1565f"
      },
      "outputs": [],
      "source": [
        "# Due to mismatch in the feature we will scale it using standard scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef7fbbf9",
      "metadata": {
        "id": "ef7fbbf9"
      },
      "outputs": [],
      "source": [
        "subset_scaled_df = custdata.apply(st.zscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "364803ba",
      "metadata": {
        "id": "364803ba"
      },
      "outputs": [],
      "source": [
        "subset_scaled_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c11c4eaa",
      "metadata": {
        "id": "c11c4eaa"
      },
      "source": [
        "## KMeans Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8dffa00",
      "metadata": {
        "id": "a8dffa00"
      },
      "source": [
        "#### Deciding number of clusters\n",
        "\n",
        "We don't know how many clusters need to build for correct grouping of data. There are multiple ways to decide the k value.\n",
        "\n",
        "Elbow plot using inertia_ which is sum of the squared distance to centroid and see where the curve bends as that value of k is best choice for the clustering. Similar elbow curve can be plotted against distortion\n",
        "\n",
        "#### validating the k value\n",
        "\n",
        "There are mutliple ways to cross validate the cluster. Popular and most used one is Silhouette Coefficient \n",
        "\n",
        "*Silhouette Coefficient* : is a value between -1 to 1 where 1 indicates tight cluster and 0 indicates overlapping cluster \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75f197d3",
      "metadata": {
        "id": "75f197d3"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "clusters = range(2, 12)\n",
        "meanDistortions = []\n",
        "\n",
        "for k in clusters:\n",
        "    model = KMeans(n_clusters=k, random_state=1)\n",
        "    model.fit(subset_scaled_df)\n",
        "    prediction = model.predict(subset_scaled_df)\n",
        "    distortion = (\n",
        "        sum(\n",
        "            np.min(cdist(subset_scaled_df, model.cluster_centers_, \"euclidean\"), axis=1)\n",
        "        )\n",
        "        / subset_scaled_df.shape[0]\n",
        "    )\n",
        "\n",
        "    meanDistortions.append(distortion)\n",
        "\n",
        "    print(\"Number of Clusters:\", k, \"\\tAverage Distortion:\", distortion)\n",
        "\n",
        "plt.plot(clusters, meanDistortions, \"bx-\")\n",
        "plt.xlabel(\"k\")\n",
        "plt.ylabel(\"Average distortion\")\n",
        "plt.title(\"Selecting k with the Elbow Method\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1a1cf7b",
      "metadata": {
        "id": "d1a1cf7b"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "clusters = range(2, 12)\n",
        "Inertias = []\n",
        "\n",
        "for k in clusters:\n",
        "    model = KMeans(n_clusters=k, random_state=1)\n",
        "    model.fit(subset_scaled_df)\n",
        "    prediction = model.predict(subset_scaled_df)\n",
        "    Inertias.append(model.inertia_)\n",
        "    print(\"Number of Clusters:\", k, \"\\tAverage Inertia:\", model.inertia_)\n",
        "\n",
        "plt.plot(clusters, Inertias, \"bx-\")\n",
        "plt.xlabel(\"k\")\n",
        "plt.ylabel(\"Average Inertias\")\n",
        "plt.title(\"Selecting k with the Elbow Method\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57d4dc98",
      "metadata": {
        "id": "57d4dc98"
      },
      "outputs": [],
      "source": [
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "model = KMeans()\n",
        "vz = KElbowVisualizer(model, k=range(2, 12), metric=\"silhouette\")\n",
        "vz.fit(subset_scaled_df)  # Fit the data to the visualizer\n",
        "vz.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59bf5c74",
      "metadata": {
        "scrolled": true,
        "id": "59bf5c74"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "inertias = []\n",
        "sils = []\n",
        "chs = []\n",
        "dbs = []\n",
        "sizes = range(2, 12)\n",
        "for k in sizes:\n",
        "    k2 = KMeans(random_state=1, n_clusters=k)\n",
        "    k2.fit(subset_scaled_df)\n",
        "    inertias.append(k2.inertia_)\n",
        "    sils.append(silhouette_score(subset_scaled_df, k2.labels_))\n",
        "    chs.append(calinski_harabasz_score(subset_scaled_df, k2.labels_))\n",
        "    dbs.append(davies_bouldin_score(subset_scaled_df, k2.labels_))\n",
        "    print(\"Silhouette Score for k {0} is {1}\".format(k, sils[k - 2]))\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "_ = (\n",
        "    pd.DataFrame(\n",
        "        {\n",
        "            \"inertia\": inertias,\n",
        "            \"sillhouttes\": sils,\n",
        "            \"calinski\": chs,\n",
        "            \"davis\": dbs,\n",
        "            \"k\": sizes,\n",
        "        },\n",
        "    )\n",
        "    .set_index(\"k\")\n",
        "    .plot(ax=ax, subplots=True, layout=(2, 2))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2ef2973",
      "metadata": {
        "scrolled": true,
        "id": "a2ef2973"
      },
      "outputs": [],
      "source": [
        "# finding optimal no. of clusters with Silhouette Visualize\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "visualizer = SilhouetteVisualizer(KMeans(2, random_state=1))\n",
        "visualizer.fit(subset_scaled_df)\n",
        "visualizer.show()\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "visualizer = SilhouetteVisualizer(KMeans(3, random_state=1))\n",
        "visualizer.fit(subset_scaled_df)\n",
        "visualizer.show()\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "visualizer = SilhouetteVisualizer(KMeans(4, random_state=1))\n",
        "visualizer.fit(subset_scaled_df)\n",
        "visualizer.show()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1790b703",
      "metadata": {
        "id": "1790b703"
      },
      "source": [
        "### Observations:\n",
        " - For silhouette Visualizer we look for \n",
        "         * clear cluster seperation and higher average Sillhouette score line, each cluster group spread extend beyond the average line\n",
        "         * for k = 3 we get clear cluster separation and average ~ 0.5\n",
        " - From all above metrics it looks like k=3 is the n_cluster value cluster can give better results   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c73c2f34",
      "metadata": {
        "id": "c73c2f34"
      },
      "source": [
        "### Run KMeans with n_clusters=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4d1d201",
      "metadata": {
        "id": "d4d1d201"
      },
      "outputs": [],
      "source": [
        "datacols = [\n",
        "    \"Avg_Credit_Limit\",\n",
        "    \"Total_Credit_Cards\",\n",
        "    \"Total_visits_bank\",\n",
        "    \"Total_visits_online\",\n",
        "    \"Total_calls_made\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50f498d7",
      "metadata": {
        "id": "50f498d7"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# let's take 3 as number of clusters\n",
        "kmeans = KMeans(n_clusters=3, random_state=0)\n",
        "kmeans.fit(subset_scaled_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6ca61c4",
      "metadata": {
        "id": "f6ca61c4"
      },
      "outputs": [],
      "source": [
        "df[\"K_means_segments\"] = kmeans.labels_\n",
        "custdata[\"K_means_segments\"] = kmeans.labels_\n",
        "subset_scaled_df[\"K_means_segments\"] = kmeans.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc3f92ce",
      "metadata": {
        "id": "dc3f92ce"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07b76223",
      "metadata": {
        "id": "07b76223"
      },
      "source": [
        "### Customer Profiling "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f93282a",
      "metadata": {
        "id": "5f93282a"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20, 6))\n",
        "for i in subset_scaled_df[\"K_means_segments\"].unique():\n",
        "    ax = fig.add_subplot(1, 3, i + 1)\n",
        "    sns.boxplot(\n",
        "        data=subset_scaled_df.loc[subset_scaled_df[\"K_means_segments\"] == i, datacols],\n",
        "        ax=ax,\n",
        "    )\n",
        "    ax.set_title(\"cluster \" + str(i))\n",
        "    plt.xticks(rotation=45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ffd2ba5",
      "metadata": {
        "id": "5ffd2ba5"
      },
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
        "subset_scaled_df.groupby(\"K_means_segments\").mean().T.plot.bar(ax=ax1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "799d89e3",
      "metadata": {
        "id": "799d89e3"
      },
      "source": [
        "### Observations:\n",
        "- For group 0 Avg_Credit_Limit, Total_Credit_Cards, Total_visits_bank forms grouping features\n",
        "- For group 1 Total_visits_online, Total_calls_made forms the grouping feature\n",
        "- For group 2 Avg_Credit_Limit,Total_Credit_Cards,Total_visits_online forms the grouping feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d264210",
      "metadata": {
        "scrolled": true,
        "id": "8d264210"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "sns.scatterplot(\n",
        "    data=df,\n",
        "    x=\"Avg_Credit_Limit\",\n",
        "    y=\"Total_visits_online\",\n",
        "    palette=\"gist_rainbow\",\n",
        "    ax=ax1,\n",
        ")\n",
        "sns.scatterplot(\n",
        "    data=df,\n",
        "    x=\"Avg_Credit_Limit\",\n",
        "    y=\"Total_visits_online\",\n",
        "    hue=\"K_means_segments\",\n",
        "    palette=\"gist_rainbow\",\n",
        "    ax=ax2,\n",
        ")\n",
        "ax1.set_title(\"Before clustering\")\n",
        "ax2.set_title(\"After clustering\")\n",
        "ax2.legend( loc=\"upper left\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2108e72",
      "metadata": {
        "id": "e2108e72"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "sns.scatterplot(\n",
        "    data=df, x=\"Customer Key\", y=\"Total_Credit_Cards\", palette=\"gist_rainbow\", ax=ax1,\n",
        ")\n",
        "sns.scatterplot(\n",
        "    data=df,\n",
        "    x=\"Customer Key\",\n",
        "    y=\"Total_Credit_Cards\",\n",
        "    hue=\"K_means_segments\",\n",
        "    palette=\"gist_rainbow\",\n",
        "    ax=ax2,\n",
        ")\n",
        "ax1.set_title(\"Before clustering\")\n",
        "ax2.set_title(\"After clustering\")\n",
        "ax2.legend(loc=\"upper left\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "425d2e59",
      "metadata": {
        "id": "425d2e59"
      },
      "outputs": [],
      "source": [
        "cluster_profile = custdata.groupby(\"K_means_segments\").mean()\n",
        "cluster_profile[\"count_in_each_segments\"] = (\n",
        "    df.groupby(\"K_means_segments\")[\"Avg_Credit_Limit\"].count().values\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d120520c",
      "metadata": {
        "id": "d120520c"
      },
      "outputs": [],
      "source": [
        "# let's display cluster profiles\n",
        "cluster_profile.style.background_gradient(cmap=\"nipy_spectral\", axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b96d183",
      "metadata": {
        "scrolled": true,
        "id": "6b96d183"
      },
      "outputs": [],
      "source": [
        "cluster_profile.style.highlight_max(color=\"lightgreen\", axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c94980c",
      "metadata": {
        "id": "2c94980c"
      },
      "source": [
        "### Observations:\n",
        "- The customers are grouped 3 clusters \n",
        "- Customers with Higher credit limits, more credit card and use online facility forms one group with customer count of lowest of the 3 , these customers do tend to make less support calls \n",
        "- Customers with lower credit limit less credit card form second group which tend to use online service but have made more support calls \n",
        "- Customers in group 0 have credit limit and credit cards between the two groups, these customes rely more on bank visit than using online facility and have second in making customer calls. This group forms majority of customer base "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "047a601a",
      "metadata": {
        "id": "047a601a"
      },
      "source": [
        "### Aggolomerative (Hirearchical) Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6bdf8d1",
      "metadata": {
        "id": "e6bdf8d1"
      },
      "outputs": [],
      "source": [
        "dfh = df.drop(\"K_means_segments\", axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab7f1ca0",
      "metadata": {
        "id": "ab7f1ca0"
      },
      "outputs": [],
      "source": [
        "hcustdata = custdata.drop(\"K_means_segments\", axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d424438",
      "metadata": {
        "id": "5d424438"
      },
      "outputs": [],
      "source": [
        "subset_scaled_hf = hcustdata.apply(st.zscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5e5c421",
      "metadata": {
        "id": "a5e5c421"
      },
      "outputs": [],
      "source": [
        "subset_scaled_hf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a458d50a",
      "metadata": {
        "id": "a458d50a"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# list of distance metrics\n",
        "distance_metrics = [\"euclidean\", \"chebyshev\", \"mahalanobis\", \"cityblock\"]\n",
        "\n",
        "# list of linkage methods\n",
        "linkage_methods = [\"single\", \"complete\", \"average\", \"weighted\"]\n",
        "\n",
        "high_cophenet_corr = 0\n",
        "high_dm_lm = [0, 0]\n",
        "\n",
        "for dm in distance_metrics:\n",
        "    for lm in linkage_methods:\n",
        "        Z = linkage(subset_scaled_hf, metric=dm, method=lm)\n",
        "        c, coph_dists = cophenet(Z, pdist(subset_scaled_hf))\n",
        "        print(\n",
        "            \"Cophenetic correlation for {} distance and {} linkage is {}.\".format(\n",
        "                dm.capitalize(), lm, c\n",
        "            )\n",
        "        )\n",
        "        if high_cophenet_corr < c:\n",
        "            high_cophenet_corr = c\n",
        "            high_dm_lm[0] = dm\n",
        "            high_dm_lm[1] = lm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66b94ff6",
      "metadata": {
        "id": "66b94ff6"
      },
      "outputs": [],
      "source": [
        "# printing the combination of distance metric and linkage method with the highest cophenetic correlation\n",
        "print(\n",
        "    \"Highest cophenetic correlation is {}, which is obtained with {} distance and {} linkage.\".format(\n",
        "        high_cophenet_corr, high_dm_lm[0].capitalize(), high_dm_lm[1]\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db250c90",
      "metadata": {
        "id": "db250c90"
      },
      "source": [
        "**Let's explore different linkage methods with Euclidean distance only.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9a1405b",
      "metadata": {
        "scrolled": false,
        "id": "a9a1405b"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# list of linkage methods\n",
        "linkage_methods = [\"single\", \"complete\", \"average\", \"centroid\", \"ward\", \"weighted\"]\n",
        "\n",
        "# lists to save results of cophenetic correlation calculation\n",
        "compare_cols = [\"Linkage\", \"Cophenetic Coefficient\"]\n",
        "compare = []\n",
        "\n",
        "# to create a subplot image\n",
        "fig, axs = plt.subplots(len(linkage_methods), 1, figsize=(15, 30))\n",
        "\n",
        "# We will enumerate through the list of linkage methods above\n",
        "# For each linkage method, we will plot the dendrogram and calculate the cophenetic correlation\n",
        "for i, method in enumerate(linkage_methods):\n",
        "    Z = linkage(subset_scaled_hf, metric=\"euclidean\", method=method)\n",
        "\n",
        "    dendrogram(Z, ax=axs[i])\n",
        "    axs[i].set_title(f\"Dendrogram ({method.capitalize()} Linkage)\")\n",
        "\n",
        "    coph_corr, coph_dist = cophenet(Z, pdist(subset_scaled_hf))\n",
        "    axs[i].annotate(\n",
        "        f\"Cophenetic\\nCorrelation\\n{coph_corr:0.2f}\",\n",
        "        (0.80, 0.80),\n",
        "        xycoords=\"axes fraction\",\n",
        "    )\n",
        "\n",
        "    compare.append([method, coph_corr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5326bc34",
      "metadata": {
        "id": "5326bc34"
      },
      "outputs": [],
      "source": [
        "# let's create a dataframe to compare cophenetic correlations for each linkage method\n",
        "df_cc = pd.DataFrame(compare, columns=compare_cols)\n",
        "df_cc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c575a660",
      "metadata": {
        "id": "c575a660"
      },
      "source": [
        "### Observations:\n",
        "\n",
        "- For dendograms we rely on which dendogram gives us clear cluster groups and have cophenetic score more that 0.50\n",
        "- From dendograms *ward* linkage with *euclidean* distance looks better choice for cluster, as it gives separate and distinct clusters \n",
        "- From cophenetic distance *average* method give better score , we will evaluate it further "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8748fc1e",
      "metadata": {
        "id": "8748fc1e"
      },
      "source": [
        "#### We will check scores for linkage *ward* and *average*  with *euclidean* "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac2e366d",
      "metadata": {
        "id": "ac2e366d"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "sils = []\n",
        "chs = []\n",
        "dbs = []\n",
        "sizes = range(2, 12)\n",
        "for k in sizes:\n",
        "    hcluster = AgglomerativeClustering(\n",
        "        n_clusters=k, affinity=\"euclidean\", linkage=\"ward\"\n",
        "    )\n",
        "    hcluster.fit(subset_scaled_hf)\n",
        "    sils.append(silhouette_score(subset_scaled_hf, hcluster.labels_))\n",
        "    chs.append(calinski_harabasz_score(subset_scaled_hf, hcluster.labels_))\n",
        "    dbs.append(davies_bouldin_score(subset_scaled_hf, hcluster.labels_))\n",
        "    print(\"Silhouette Score for k {0} is {1}\".format(k, sils[k - 2]))\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "_ = (\n",
        "    pd.DataFrame({\"sillhouttes\": sils, \"calinski\": chs, \"davis\": dbs, \"k\": sizes,},)\n",
        "    .set_index(\"k\")\n",
        "    .plot(ax=ax, subplots=True, layout=(2, 2))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cedd5a9a",
      "metadata": {
        "scrolled": true,
        "id": "cedd5a9a"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "sils = []\n",
        "chs = []\n",
        "dbs = []\n",
        "sizes = range(2, 12)\n",
        "for k in sizes:\n",
        "    hcluster = AgglomerativeClustering(\n",
        "        n_clusters=k, affinity=\"euclidean\", linkage=\"average\"\n",
        "    )\n",
        "    hcluster.fit(subset_scaled_hf)\n",
        "    sils.append(silhouette_score(subset_scaled_hf, hcluster.labels_))\n",
        "    chs.append(calinski_harabasz_score(subset_scaled_hf, hcluster.labels_))\n",
        "    dbs.append(davies_bouldin_score(subset_scaled_hf, hcluster.labels_))\n",
        "    print(\"Silhouette Score for k {0} is {1}\".format(k, sils[k - 2]))\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "_ = (\n",
        "    pd.DataFrame({\"sillhouttes\": sils, \"calinski\": chs, \"davis\": dbs, \"k\": sizes,},)\n",
        "    .set_index(\"k\")\n",
        "    .plot(ax=ax, subplots=True, layout=(2, 2))\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1789524",
      "metadata": {
        "id": "e1789524"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "811d4112",
      "metadata": {
        "id": "811d4112"
      },
      "source": [
        "### Observations:\n",
        " - for good cluster \n",
        "       * Sillhouette score must be between -1 to 1 but higher is better\n",
        "       * calinski score is 0 and up but higher is better\n",
        "       * davis score is 0 and up but lower is better\n",
        " \n",
        " - with *ward* linkage we get match for all 3 score at k = 3\n",
        " - with *Average* we get random results for all 3 scores \n",
        " \n",
        " \n",
        " *For Agglomerative Clustering we will go with k = 3*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20bd750b",
      "metadata": {
        "id": "20bd750b"
      },
      "source": [
        "### Modeling "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e8e3712",
      "metadata": {
        "id": "1e8e3712"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "hcluster = AgglomerativeClustering(n_clusters=3, affinity=\"euclidean\", linkage=\"ward\")\n",
        "hcluster.fit(subset_scaled_hf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6d1529b",
      "metadata": {
        "id": "d6d1529b"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4948ccd8",
      "metadata": {
        "id": "4948ccd8"
      },
      "outputs": [],
      "source": [
        "dfh[\"hcluster_segments\"] = hcluster.labels_\n",
        "hcustdata[\"hcluster_segments\"] = hcluster.labels_\n",
        "subset_scaled_hf[\"hcluster_segments\"] = hcluster.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b9e788c",
      "metadata": {
        "id": "6b9e788c"
      },
      "outputs": [],
      "source": [
        "subset_scaled_hf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d48f75d1",
      "metadata": {
        "id": "d48f75d1"
      },
      "source": [
        "### Customer Profiling "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f61e0f5",
      "metadata": {
        "id": "1f61e0f5"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20, 6))\n",
        "for i in subset_scaled_hf[\"hcluster_segments\"].unique():\n",
        "    ax = fig.add_subplot(1, 3, i + 1)\n",
        "    sns.boxplot(\n",
        "        data=subset_scaled_df.loc[subset_scaled_hf[\"hcluster_segments\"] == i, datacols],\n",
        "        ax=ax,\n",
        "    )\n",
        "    ax.set_title(\"cluster \" + str(i))\n",
        "    plt.xticks(rotation=45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cef0900",
      "metadata": {
        "id": "5cef0900"
      },
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
        "subset_scaled_hf.groupby(\"hcluster_segments\").mean().T.plot.bar(ax=ax1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e355d97",
      "metadata": {
        "id": "6e355d97"
      },
      "source": [
        "### Observations:\n",
        "- For group 0 Avg_Credit_Limit, Total_Credit_Cards, Total_visits_bank forms grouping features \n",
        "- For group 1 Total_visits_online, Total_calls_made forms the grouping feature \n",
        "- For group 2 Avg_Credit_Limit,Total_Credit_Cards,Total_visits_online forms the grouping feature "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c541d0f",
      "metadata": {
        "id": "6c541d0f"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "sns.scatterplot(\n",
        "    data=dfh,\n",
        "    x=\"Avg_Credit_Limit\",\n",
        "    y=\"Total_visits_online\",\n",
        "    palette=\"gist_rainbow\",\n",
        "    ax=ax1,\n",
        ")\n",
        "sns.scatterplot(\n",
        "    data=dfh,\n",
        "    x=\"Avg_Credit_Limit\",\n",
        "    y=\"Total_visits_online\",\n",
        "    hue=\"hcluster_segments\",\n",
        "    palette=\"gist_rainbow\",\n",
        "    ax=ax2,\n",
        ")\n",
        "ax1.set_title(\"Before clustering\")\n",
        "ax2.set_title(\"After clustering\")\n",
        "ax2.legend( loc=\"upper left\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3599a17",
      "metadata": {
        "id": "f3599a17"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "sns.scatterplot(\n",
        "    data=dfh, x=\"Customer Key\", y=\"Total_Credit_Cards\", palette=\"gist_rainbow\", ax=ax1,\n",
        ")\n",
        "sns.scatterplot(\n",
        "    data=dfh,\n",
        "    x=\"Customer Key\",\n",
        "    y=\"Total_Credit_Cards\",\n",
        "    hue=\"hcluster_segments\",\n",
        "    palette=\"gist_rainbow\",\n",
        "    ax=ax2,\n",
        ")\n",
        "ax1.set_title(\"Before clustering\")\n",
        "ax2.set_title(\"After clustering\")\n",
        "ax2.legend(loc=\"upper left\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f54de293",
      "metadata": {
        "id": "f54de293"
      },
      "outputs": [],
      "source": [
        "cluster_profile_h = hcustdata.groupby(\"hcluster_segments\").mean()\n",
        "cluster_profile_h[\"count_in_each_segments\"] = (\n",
        "    dfh.groupby(\"hcluster_segments\")[\"Avg_Credit_Limit\"].count().values\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0b5374b",
      "metadata": {
        "scrolled": false,
        "id": "b0b5374b"
      },
      "outputs": [],
      "source": [
        "# let's display cluster profiles\n",
        "cluster_profile_h.style.background_gradient(cmap=\"nipy_spectral\", axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d65a0f6",
      "metadata": {
        "id": "0d65a0f6"
      },
      "outputs": [],
      "source": [
        "cluster_profile_h.style.highlight_max(color=\"lightgreen\", axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cd8af95",
      "metadata": {
        "id": "5cd8af95"
      },
      "source": [
        "### Observations:\n",
        "- The customers are grouped 3 clusters \n",
        "- Customers with Higher credit limits, more credit card and use online facility forms one group with customer count of lowest of the 3 , these customers do tend to make less support calls \n",
        "- Customers with lower credit limit less credit card form second group which tend to use online service but have made more support calls \n",
        "- Customers in group 0 have credit limit and credit cards between the two groups, these customes rely more on bank visit than using online facility and have second in making customer calls. This group forms majority of customer base "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e68b1a3",
      "metadata": {
        "id": "4e68b1a3"
      },
      "source": [
        "### Compare the cluster profile of both the methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7efa836",
      "metadata": {
        "id": "d7efa836"
      },
      "outputs": [],
      "source": [
        "print(\"\\t\\tCluster profile for Agglomerative Clustering\")\n",
        "cluster_profile_h.style.highlight_max(color=\"lightgreen\", axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fc3880d",
      "metadata": {
        "id": "7fc3880d"
      },
      "outputs": [],
      "source": [
        "print(\"\\t\\tCluster profile for KMeans Clustering\")\n",
        "cluster_profile.style.highlight_max(color=\"lightgreen\", axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fc47c74",
      "metadata": {
        "id": "4fc47c74"
      },
      "source": [
        "### Observations\n",
        "- Both clustering models gives similar results \n",
        "- There are no major deviations found between models\n",
        "- Clustering criteria remains same across both the models\n",
        "- Sillhoutte score is also same across both the models \n",
        "- There is no specific differecing criteria that can be applied to select perticular algorithm over the other but in general KMeans is may work efficintly with large dataset.\n",
        "- Experiment with Larger dataset needed before selection of model can be made "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5f2dd41",
      "metadata": {
        "id": "f5f2dd41"
      },
      "source": [
        "### Actionable Insights & Recommendations\n",
        "\n",
        "- It looks like customer in group 2 use more online facility and tend to make less number of customer support calls , May be these customer are from higher income , higher online banking awareness class have mastered online banking  \n",
        "\n",
        "- Customer in group 1 with lower credit Limits and lower credit cards , thise group tend to use online facility but have more customer support calls. This can be a possible indications of non user friendly online service, or opportunity to improve online service.\n",
        "\n",
        "- Group 0 customers make more visit to bank and have lower online presence, they also have moderate number of customer support calls. Bank need to investigate reasons why these customer do not use online service and address the concerns if they related to techonology. These will help reduce the workload of banking staff.\n",
        "\n",
        "- Group 0 customers have moderate number of credit cards with good credit limits and should be encouraged to use them with additional returns.  \n",
        "\n",
        "- Bank need to focus on group 1 to address their concerns as this group try to use online service but not able to make their way. Addressing these set of customer can help increate more credit card usage and business opportunity \n",
        "\n",
        "- Bank need to review its online service, talking to the customers and support team to identify the issues in online service and fix it \n",
        "\n",
        "- Reviwing online banking service will help increase the business and also reduce the # complaints about customer support "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8182cc7b",
      "metadata": {
        "id": "8182cc7b"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "all_bank_customer_segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "cfea9ba5",
        "75abbd5b",
        "8ad604a6",
        "d922dfdd",
        "9d890d10",
        "c252a1d1",
        "e1b12f26",
        "66aaccc0",
        "697c6b67",
        "a8dffa00",
        "1790b703",
        "c73c2f34",
        "07b76223",
        "799d89e3",
        "2c94980c",
        "047a601a",
        "c575a660",
        "8748fc1e",
        "811d4112",
        "20bd750b",
        "d48f75d1",
        "6e355d97",
        "5cd8af95",
        "4e68b1a3",
        "4fc47c74",
        "f5f2dd41"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}